unix_socket_directories = '/tmp'
max_connections = 300 # Each worker consumes (at most) work_mem (16MB) + temp_buffers (16MB) = 32MB (plus a tiny bit of overhead).
shared_buffers = 3096MB # The rule of thumb for dedicated servers is 25% of available RAM.
temp_buffers = 16MB
work_mem = 16MB
maintenance_work_mem = 128MB
shared_preload_libraries = 'pg_stat_statements,pgaudit,timescaledb'
#
log_checkpoints = off
log_connections = off
log_disconnections = off
log_lock_waits = on
log_temp_files = 0
log_autovacuum_min_duration = 0
log_error_verbosity = default
log_statement = none
log_min_duration_statement = 100
log_line_prefix = '%m [%p] %d:'
pg_stat_statements.max = 10000
pg_stat_statements.track = all

#
# Increase the max size of the query strings Postgres records
track_activity_query_size = 2048

# Track statements generated by stored procedures as well
pg_stat_statements.track = all

#
password_encryption = md5
#
idle_session_timeout = 86400s

#
checkpoint_completion_target = 0.9
max_wal_size = 3096MB
min_wal_size = 1024MB
checkpoint_timeout = 1200s # 20 mins
#checkpoint_completion_targe = 1.0 # depr in pg_14

#
random_page_cost = 1.1
seq_page_cost = 0.1
cpu_tuple_cost = 0.02

autovacuum_vacuum_cost_limit = 3000
enable_partitionwise_aggregate = on
enable_partitionwise_join = on
cpu_index_tuple_cost = 0.5
cpu_index_tuple_cost = 0.006
cpu_operator_cost = 0.0025
parallel_setup_cost = 1000
parallel_tuple_cost = 0.1

# Schedule jobs via background workers instead of localhost connections
cron.use_background_workers = on
# Increase the number of available background workers from the default of 8
max_worker_processes = 20
# Connect via a unix domain socket

# Connect via a unix domain socket
#cron.host = '/tmp'
#cron.database_name = 'postgres'

### config v1.0.0
log_autovacuum_min_duration = -1  # -1 disables, 0 logs all actions and
autovacuum = on
log_line_prefix = '%m | %p | %h | %d |'
pg_stat_statements.max = 10000
pg_stat_statements.track = all
log_min_duration_statement = 0
max_locks_per_transaction = 800
